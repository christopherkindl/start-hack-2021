{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "# autosave every 60 seconds\n",
    "%autosave 60\n",
    "\n",
    "#display full output in Notebook, instead of only the last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "#standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "    \n",
    "#ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "#ARIMA model\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "#indicate how many differencing rounds are necessary\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "\n",
    "#preprocessing libraries\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "\n",
    "#model libraries\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "#viz\n",
    "import seaborn as sns\n",
    "# plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#store model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "data_path = '/Users/christopherkindl/working/start-hack-2021/00_data/'\n",
    "\n",
    "#define variables\n",
    "rapperswil_data = 'rapperswil.csv'\n",
    "burgdorf_data = 'burgdorf.csv'\n",
    "weather_data = 'weather_rapperswil.csv'\n",
    "\n",
    "#function to import data\n",
    "def load_data(data_path, data_type):\n",
    "    csv_path = os.path.join(data_path, data_type)\n",
    "    return pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "#function to import data (,)\n",
    "def load_data_2(data_path, data_type):\n",
    "    csv_path = os.path.join(data_path, data_type)\n",
    "    return pd.read_csv(csv_path, sep=',')\n",
    "\n",
    "#load rapperswil data\n",
    "df_weather = load_data_2(data_path, weather_data)\n",
    "df_rapperswil = load_data(data_path, rapperswil_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df_rapperswil = df_rapperswil.rename(columns={'Datum': 'date', 'BELEGUNGSQUOTE (%)': 'occupancy_rate'})\n",
    "\n",
    "#convert date column into datetime format\n",
    "df_rapperswil['date'] = pd.to_datetime(df_rapperswil['date'])\n",
    "\n",
    "#remove time zone\n",
    "df_rapperswil['date'] = df_rapperswil['date'].apply(lambda x: x.replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the following features as relevant:\n",
    "\n",
    "**Date-time features:**\n",
    "- Hour\n",
    "- Day of week\n",
    "- Quarter\n",
    "- Month\n",
    "- Day of year\n",
    "- Day of month\n",
    "- Week of year\n",
    "\n",
    "**Local features:**\n",
    "- Weather type\n",
    "- Temperature (Fahrenheit)\n",
    "- Public holiday or not (Coming soon)\n",
    "\n",
    "**Lag features:** (TBD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date-time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(df, label=None):\n",
    "    \"\"\"\n",
    "    Input initial df of parking lots (e.g. df_rapperswil).\n",
    "    Create several time dimensions, such as quarter or day of week.\n",
    "    Return df with new time dimensions.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    #df['id'] = df.index\n",
    "    df['date_only'] = df['date'].dt.date\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    #df['day_name'] = df['date'].dt.day_name()\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    #df['year'] = df['date'].dt.year\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['week_of_year'] = df['date'].dt.weekofyear\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapperswil = time_features(df_rapperswil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-77b20841dd74>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather['date'] = pd.to_datetime(df_weather['dt'], unit='s')\n",
      "/Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#only keep essential columns\n",
    "df_weather = df_weather[['dt', 'temp', 'weather_main']]\n",
    "\n",
    "#convert date column into datetime format\n",
    "df_weather['date'] = pd.to_datetime(df_weather['dt'], unit='s')\n",
    "\n",
    "# keep only essential columns\n",
    "# df_weather = df_weather[['date', 'weather_main']]\n",
    "\n",
    "#drop dt column\n",
    "df_weather.drop(columns=['dt'], inplace = True)\n",
    "\n",
    "# rename columns\n",
    "df_weather = df_weather.rename(columns={'weather_main': 'weather', 'temp' : 'temperature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "df_rapperswil = time_features(df_rapperswil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge weather data with parking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_rapperswil, df_weather, how='inner', on = 'date')\n",
    "\n",
    "# drop date_only column\n",
    "merged_df = merged_df.drop('date_only', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date as index\n",
    "merged_df.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling, training and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) General configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X, y = merged_df.drop('occupancy_rate', axis=1), merged_df[['occupancy_rate']]\n",
    "\n",
    "# number of cross-validation rounds for model evaluation\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Pre-processing pipeline\n",
    "- drop (or impute) Nan values\n",
    "- encode features\n",
    "- standardise features (scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform categorical values into integers\n",
    "X['weather_num'] = pd.Categorical(X['weather'])\n",
    "X['weather_num'] = X.weather_num.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-12fa8e0ca122>:3: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data_cat = X.select_dtypes(include=[np.object])\n"
     ]
    }
   ],
   "source": [
    "#split numerical and categorical columns\n",
    "data_num = X.select_dtypes(include=[np.number])\n",
    "data_cat = X.select_dtypes(include=[np.object])\n",
    "\n",
    "#create data pipeline\n",
    "num_pipeline = Pipeline([('std_scaler', StandardScaler())])\n",
    "\n",
    "num_attribs = list(data_num)\n",
    "cat_attribs = list(data_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', OneHotEncoder(), cat_attribs), \n",
    "    ])\n",
    "\n",
    "X = full_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign initial colum names in seperate list\n",
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "cat_encoder = list(cat_encoder.categories_)\n",
    "cat_encoder_attribs = [str(cat_attribs[index]) + '_' + category for index,categories \n",
    "                       in enumerate(cat_hot_attribs) for category in categories]\n",
    "attributes = num_attribs + cat_encoder_attribs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/christopherkindl/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Root Meat Squared Error is: 7.71417\n"
     ]
    }
   ],
   "source": [
    "# run cross-validation\n",
    "\n",
    "# Init RF and CV\n",
    "cv = TimeSeriesSplit(n_splits=3)\n",
    "rf = RandomForestRegressor(n_estimators=250, random_state=42) # will be optimised by grid search\n",
    "\n",
    "scores = cross_validate(rf, X, y, cv=cv, scoring='neg_mean_squared_error', return_estimator=True)\n",
    "\n",
    "# Base RMSLE\n",
    "base_rmsle = np.sqrt(-np.mean(scores[\"test_score\"]))\n",
    "print(\"Base Root Meat Squared Error is: {:.5f}\".format(base_rmsle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score for estimator 0:\n",
      "-----------------------------------------------\n",
      "                      importance\n",
      "hour                    0.758953\n",
      "temperature             0.119762\n",
      "day_of_week             0.048661\n",
      "day_of_year             0.034109\n",
      "day_of_month            0.014885\n",
      "week_of_year            0.011609\n",
      "month                   0.002842\n",
      "weather_Clear           0.001690\n",
      "quarter                 0.001561\n",
      "weather_Rain            0.001538\n",
      "weather_Clouds          0.001481\n",
      "weather_Fog             0.001080\n",
      "weather_Mist            0.000775\n",
      "weather_Snow            0.000595\n",
      "weather_Drizzle         0.000285\n",
      "weather_Thunderstorm    0.000115\n",
      "weather_Haze            0.000058\n",
      "Features sorted by their score for estimator 1:\n",
      "-----------------------------------------------\n",
      "                      importance\n",
      "hour                    0.765452\n",
      "temperature             0.120031\n",
      "day_of_week             0.048495\n",
      "day_of_year             0.031244\n",
      "day_of_month            0.011551\n",
      "week_of_year            0.010869\n",
      "month                   0.003441\n",
      "weather_Clear           0.002003\n",
      "weather_Rain            0.001907\n",
      "quarter                 0.001342\n",
      "weather_Clouds          0.001181\n",
      "weather_Snow            0.000761\n",
      "weather_Fog             0.000734\n",
      "weather_Mist            0.000630\n",
      "weather_Drizzle         0.000200\n",
      "weather_Thunderstorm    0.000100\n",
      "weather_Haze            0.000060\n",
      "Features sorted by their score for estimator 2:\n",
      "-----------------------------------------------\n",
      "                      importance\n",
      "hour                    0.762791\n",
      "temperature             0.115294\n",
      "day_of_week             0.055057\n",
      "day_of_year             0.031740\n",
      "day_of_month            0.011899\n",
      "week_of_year            0.009850\n",
      "weather_Clear           0.003271\n",
      "month                   0.003064\n",
      "weather_Rain            0.002051\n",
      "quarter                 0.001654\n",
      "weather_Clouds          0.001450\n",
      "weather_Fog             0.000476\n",
      "weather_Mist            0.000475\n",
      "weather_Snow            0.000444\n",
      "weather_Thunderstorm    0.000253\n",
      "weather_Drizzle         0.000175\n",
      "weather_Haze            0.000055\n"
     ]
    }
   ],
   "source": [
    "#get feature importance\n",
    "for idx,estimator in enumerate(scores['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                       index = attributes,\n",
    "                                       columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print('-----------------------------------------------')\n",
    "    print(feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
