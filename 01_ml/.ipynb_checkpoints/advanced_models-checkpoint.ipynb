{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full output in Notebook, instead of only the last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# customized preprocessing functions\n",
    "import util\n",
    "\n",
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# models\n",
    "from pmdarima import auto_arima\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../00_data\"\n",
    "\n",
    "df_rapperswil = pd.read_csv(os.path.join(data_path, \"features_rapperswil.csv\"), sep=\",\")\n",
    "# df_burgdorf = pd.read_csv(os.path.join(data_path, \"features_burgdorf.csv\"), sep=\",\")\n",
    "\n",
    "print('Dataset shape of Rapperswil data: {}'.format(df_rapperswil.shape))\n",
    "print('Dataset shape of Burgdorf data: {}'.format(df_burgdorf.shape))\n",
    "\n",
    "df_rapperswil['date'] = pd.to_datetime(df_rapperswil['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  rapperswil declare categorical columns\n",
    "for col in ['hour', 'day_of_week', 'quarter', 'month', 'day_of_year', 'day_of_month', 'week_of_year', 'weather', 'holiday']:\n",
    "    df_rapperswil[col] = df_rapperswil[col].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(df, label=None):\n",
    "    X = df[[ 'date_only',\n",
    "             'hour',\n",
    "             'day_of_week',\n",
    "             'quarter',\n",
    "             'month',\n",
    "             'day_of_year',\n",
    "             'day_of_month',\n",
    "             'week_of_year',\n",
    "             'temperature',\n",
    "             'weather',\n",
    "             'holiday',\n",
    "             't-7',\n",
    "             't-3',\n",
    "             't-2',\n",
    "             't-1']]\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split(df_rapperswil, '2021-07-01 01:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data sets\n",
    "X_train, y_train = split_features(df_train, label='occupancy_rate')\n",
    "X_test, y_test = split_features(df_test, label='occupancy_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature scaling** \\\n",
    "Features vary in magnitude and units, which is why we apply feature scaling using `StandardScaler()` for numeric features and `OneHotEncoder()` for categorical features. For example, the input value `day_of_week` should not be used as a continuous value from 1 to 7, since this would mean that the last weekdays (5, 6 or 7) are associated to a higher\n",
    "weight than the first ones (1,2 and 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split numerical and categorical columns\n",
    "data_num = X_train.select_dtypes(include=[np.number])\n",
    "data_cat = X_train.select_dtypes(include=[np.object])\n",
    "\n",
    "# create data pipeline\n",
    "num_pipeline = Pipeline([('std_scaler', StandardScaler())])\n",
    "\n",
    "num_attribs = list(data_num)\n",
    "cat_attribs = list(data_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', OneHotEncoder(), cat_attribs)])\n",
    "\n",
    "#Â fit and transform training data set with preprocessing pipeline and\n",
    "# only transform test feature set with the pipeline fit on training feature set to not\n",
    "# artificially improve test performance\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train)\n",
    "X_test = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hyperparameter optimization, we apply `random grid search` with cross validation to narrow down the range of reasonable values for the given parameters for the models. Then, `full grid search` with cross validation is applied with the value range obtained from the random grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Define random grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees in random forest\n",
    "n_estimators = [x for x in range(200, 2000, 25)]\n",
    "\n",
    "# number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# create grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the random grid to search for best hyperparameters\n",
    "\n",
    "# create random forest model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# ensure prediction is made on subsequent data\n",
    "cv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# random search of parameters, using 3 fold cross validation, \n",
    "# search across 75 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 75, cv = cv,\n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "#s how best parameters\n",
    "print('Best parameters:')\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Define new grid with optimal value range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define more specific grid\n",
    "\n",
    "# number of trees in random forest\n",
    "n_estimators = [x for x in range(200, 2000, 25)]\n",
    "\n",
    "# number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# create grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# ensure prediction is made on subsequent data\n",
    "cv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# random search of parameters, using 3 fold cross validation, \n",
    "# search across 75 different combinations, and use all available cores\n",
    "rf = GridSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 75, cv = cv,\n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# fit the random search model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# show best parameters\n",
    "print('Best parameters:')\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Fit model with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 42,\n",
    "                           n_estimators = 600,\n",
    "                           max_features = 'auto',\n",
    "                           max_depth = 20,\n",
    "                           min_samples_split = 2,\n",
    "                           min_samples_leaf = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the random search model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# run prediction\n",
    "df_test['random_forest'] = rf.predict(X_test)\n",
    "df_all = pd.concat([df_test, df_train], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', round(mean_absolute_error(y_true=df_test['occupancy_rate'], y_pred=df_test['random_forest']), 2))\n",
    "print('RMSE: ', round(mean_squared_error(y_true=df_test['occupancy_rate'], y_pred=df_test['random_forest'], squared=False), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Optimal parameters obtained from last random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBRegressor(n_estimators = 600,\n",
    "                            min_child_weight = 17,\n",
    "                            max_leaf_nodes = 110,\n",
    "                            # max_features = 'auto',\n",
    "                            max_depth = 51,\n",
    "                            gamma = 0,\n",
    "                            eta = 0.01,\n",
    "                            colsample_bytree = 0.9,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the random search model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# run prediction\n",
    "df_test['f1 features'] = xgb.predict(X_test)\n",
    "df_all = pd.concat([df_test, df_train], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Performance: 3.93 (MAE), 6.03 (RMSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', round(mean_absolute_error(y_true=df_test['occupancy_rate'], y_pred=df_test['f1 features']), 2))\n",
    "print('RMSE: ', round(mean_squared_error(y_true=df_test['occupancy_rate'], y_pred=df_test['f1 features'], squared=False), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the true target values for the test set versus the estimated values with the best model\n",
    "plt.scatter(df_test['occupancy_rate'], df_test['time-related features'], alpha=0.1);\n",
    "plt.plot([0, 100], [0, 100], \"k--\", lw=3);\n",
    "plt.xlabel('Measured parking occupancy (%)');\n",
    "plt.ylabel('Predicted parking occupancy (%)');\n",
    "plt.title('F1 features: True values vs predicted values');\n",
    "file = 'f1_features.png'\n",
    "plt.savefig('../05_visualisations_of_eda/' + file);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
