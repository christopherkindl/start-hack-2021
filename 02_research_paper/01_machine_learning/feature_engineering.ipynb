{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the data is located and the engineered features will be saved.\n",
    "data_path = '../00_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full output in Notebook, instead of only the last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "    \n",
    "# ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length of Rapperswil data: 12324\n",
      "Dataset length of Burgdorf data: 7789\n"
     ]
    }
   ],
   "source": [
    "# file names\n",
    "rapperswil_data = 'rapperswil.csv'\n",
    "burgdorf_data = 'burgdorf.csv'\n",
    "weather_rapperswil = 'weather_rapperswil.csv'\n",
    "weather_burgdorf = 'weather_burgdorf.csv'\n",
    "public_holidays_rapperswil = 'public_holidays_zurich.csv'\n",
    "public_holidays_bern = 'public_holidays_bern.csv'\n",
    "ticket_sales_rapperswil = 'ticket_sales_rapperswil.csv'\n",
    "ticket_sales_burgdorf = 'ticket_sales_burgdorf.csv'\n",
    "\n",
    "# function to import data\n",
    "def load_data(data_path, data_file, **kwargs):\n",
    "    csv_path = os.path.join(data_path, data_file)\n",
    "    return pd.read_csv(csv_path, **kwargs)\n",
    "\n",
    "# load weather data\n",
    "df_weather_rapperswil = load_data(data_path, weather_rapperswil, sep=',')\n",
    "df_weather_burgdorf = load_data(data_path, weather_burgdorf, sep=',')\n",
    "\n",
    "# load parking data\n",
    "df_rapperswil = load_data(data_path, rapperswil_data, sep=',')\n",
    "df_burgdorf = load_data(data_path, burgdorf_data, sep=';', usecols=['date', 'occupancy_rate'])\n",
    "\n",
    "# load ticket sales data\n",
    "df_sales_rapperswil = load_data(data_path, ticket_sales_rapperswil, sep = ';', usecols=['Start'])\n",
    "df_sales_burgdorf = load_data(data_path, ticket_sales_burgdorf, sep = ';', usecols=['Start'])\n",
    "\n",
    "# load public holiday data\n",
    "# columns to keep\n",
    "df_holidays_rapperswil = load_data(data_path, public_holidays_rapperswil, sep=';', encoding='latin1', usecols=['Date'])\n",
    "df_holidays_burgdorf = load_data(data_path, public_holidays_bern, sep=';', encoding='latin1', usecols=['Date'])\n",
    "\n",
    "print('Dataset length of Rapperswil data: {}'.format(len(df_rapperswil)))\n",
    "print('Dataset length of Burgdorf data: {}'.format(len(df_burgdorf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) Public holiday data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.feiertagskalender.ch/\n",
    "\n",
    "columns:\n",
    "- **date:** represents a public holiday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Date column to date and convert to timestamp\n",
    "df_holidays_rapperswil = df_holidays_rapperswil.rename(columns={'Date' : 'date'})\n",
    "df_holidays_rapperswil['date'] = [datetime.strptime(i, '%d.%m.%Y').date() for i in df_holidays_rapperswil.date]\n",
    "\n",
    "df_holidays_burgdorf = df_holidays_burgdorf.rename(columns={'Date' : 'date'})\n",
    "df_holidays_burgdorf['date'] = [datetime.strptime(i, '%d.%m.%Y').date() for i in df_holidays_burgdorf.date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Parking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns:\n",
    "- **datetime:** hourly\n",
    "- **occupancy_rate:** avg. parking occupancy for given hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df_rapperswil = df_rapperswil.rename(columns={'DATE': 'date', 'BELEGUNGSQUOTE (%)': 'occupancy_rate'})\n",
    "df_burgdorf = df_burgdorf.rename(columns={'category': 'date', 'Auslastung': 'occupancy_rate'})\n",
    "\n",
    "#convert date column into datetime format\n",
    "df_rapperswil['date'] = pd.to_datetime(df_rapperswil['date'])\n",
    "df_burgdorf['date'] = pd.to_datetime(df_burgdorf['date'])\n",
    "\n",
    "#remove time zone\n",
    "df_rapperswil['date'] = df_rapperswil['date'].apply(lambda x: x.replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Ticket sales data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_sales_cleaning(df_sales):\n",
    "    \n",
    "    # delete time zone information\n",
    "    df_sales['Start'] = pd.to_datetime(df_sales['Start'])\n",
    "    df_sales['Start'] = df_sales['Start'].apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "    # change column name\n",
    "    df_sales = df_sales.rename(columns={'Start': 'date'})\n",
    "\n",
    "    # round down to the hour\n",
    "    df_sales['date'] = df_sales['date'].apply(lambda x: x.replace(microsecond=0, second=0, minute=0))\n",
    "\n",
    "    # use index as column for a more convenient aggregation\n",
    "    df_sales['id'] = df_sales.index\n",
    "\n",
    "    # create new df by aggregating ticket sales per full hour\n",
    "    df_sales = pd.DataFrame(df_sales.groupby(['date'])['id'].count())\n",
    "\n",
    "    # rename column\n",
    "    df_sales = df_sales.rename(columns={'id': 'sales'})\n",
    "    \n",
    "    # set index as new column\n",
    "    df_sales['date'] = df_sales.index\n",
    "    \n",
    "    df_sales.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cleaning function to both ticket sales data set\n",
    "df_sales_rapperswil = ticket_sales_cleaning(df_sales_rapperswil)\n",
    "df_sales_burgdorf = ticket_sales_cleaning(df_sales_burgdorf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://home.openweathermap.org/history_bulks/new (fee required)\n",
    "\n",
    "columns:\n",
    "- **temperature** (kelvin)\n",
    "- **weather:** rain, clear, clouds, etc.\n",
    "- **datetime:** hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep essential columns\n",
    "df_weather_rapperswil = df_weather_rapperswil[['dt', 'temp', 'weather_main']]\n",
    "df_weather_burgdorf = df_weather_burgdorf[['dt', 'temp', 'weather_main']]\n",
    "\n",
    "# convert date column into datetime format\n",
    "df_weather_rapperswil['date'] = pd.to_datetime(df_weather_rapperswil['dt'], unit='s')\n",
    "df_weather_burgdorf['date'] = pd.to_datetime(df_weather_burgdorf['dt'], unit='s')\n",
    "\n",
    "# drop dt column\n",
    "df_weather_rapperswil.drop(columns=['dt'], inplace = True)\n",
    "df_weather_burgdorf.drop(columns=['dt'], inplace = True)\n",
    "\n",
    "# rename columns\n",
    "df_weather_rapperswil = df_weather_rapperswil.rename(columns={'weather_main': 'weather', 'temp' : 'temperature'})\n",
    "df_weather_burgdorf = df_weather_burgdorf.rename(columns={'weather_main': 'weather', 'temp' : 'temperature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the following variables as relevant for feature-based models:\n",
    "\n",
    "**Features based on internal data:**\n",
    "- Hour\n",
    "- Day of week\n",
    "- Quarter\n",
    "- Month\n",
    "- Day of year\n",
    "- Day of month\n",
    "- Week of year\n",
    "- occupancy rate $t-1$\n",
    "- occupancy rate $t-2$\n",
    "- occupancy rate $t-3$\n",
    "- occupancy rate $t-7$\n",
    "- ticket sales $t-1$\n",
    "- ticket sales $t-2$\n",
    "- ticket sales $t-3$\n",
    "- ticket sales $t-7$\n",
    "\n",
    "**Features based on external data:**\n",
    "- Weather type (clouds, rain, snow, etc.)\n",
    "- Weather type $t-1$\n",
    "- Weather type $t-2$\n",
    "- Weather type $t-3$\n",
    "- Weather type $t-7$\n",
    "- Temperature (Kelvin)\n",
    "- Temperature (Kelvin) $t-1$\n",
    "- Temperature (Kelvin) $t-2$\n",
    "- Temperature (Kelvin) $t-3$\n",
    "- Temperature (Kelvin) $t-7$\n",
    "- Public holiday (boolean value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on internal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(df):\n",
    "    \"\"\"\n",
    "    Input parking data.\n",
    "    Creates several time dimensions, such as quarter or day of week.\n",
    "    Return df with historical features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['date_only'] = df['date'].dt.date # only for visualization purposes, not a feature\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_name'] = df['date'].dt.day_name()\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['week_of_year'] = df['date'].dt.weekofyear\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create historical features\n",
    "df_rapperswil = time_features(df_rapperswil)\n",
    "df_burgdorf = time_features(df_burgdorf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge parking data with ticket sales data and add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ticket sales data with parking data\n",
    "df_rapperswil = pd.merge(df_rapperswil, df_sales_rapperswil, how='left', on='date')\n",
    "df_burgdorf = pd.merge(df_burgdorf, df_sales_burgdorf, how='left', on='date')\n",
    "\n",
    "# replace nan values in sales column with 0\n",
    "df_rapperswil['sales'] = df_rapperswil['sales'].fillna(0)\n",
    "df_burgdorf['sales'] = df_burgdorf['sales'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12324"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rapperswil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features_sales(df_p):\n",
    "    df_park = df_p.copy()\n",
    "\n",
    "    # prepare lag data \n",
    "    df_lags = pd.concat([df_park['sales'].shift(7),\n",
    "                        df_park['sales'].shift(3),\n",
    "                        df_park['sales'].shift(2),\n",
    "                        df_park['sales'].shift(1)], axis=1)\n",
    "\n",
    "    df_lags.columns = ['sales_t-7', 'sales_t-3', 'sales_t-2', 'sales_t-1']\n",
    "\n",
    "    # join lag df with parking and lag data\n",
    "    df_park = pd.concat([df_lags, df_park], axis=1)\n",
    "    \n",
    "    # drop rows that contain NaN values caused by shifting\n",
    "    df_park.dropna(inplace=True)\n",
    "    \n",
    "    # drop sales column as only lag values are of interest \n",
    "    df_park.drop('sales', axis=1, inplace=True)\n",
    "\n",
    "    # set datetime as index\n",
    "    # df_park = df_park.set_index('date')\n",
    "\n",
    "    return df_park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2476\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "# apply lag features for sales data to both sets\n",
    "df_rapperswil = lag_features_sales(df_rapperswil)\n",
    "df_burgdorf = lag_features_sales(df_burgdorf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on external data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for related features (weather, holidays) already exists and, thus, needs to be merged with parking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Merge weather data, parking and public holidays data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather(df_p, df_w):\n",
    "    df_park = df_p.copy()\n",
    "    df_weather = df_w.copy()\n",
    "\n",
    "    # set datetime as index for merging\n",
    "    df_weather.set_index('date')\n",
    "    df_park.set_index('date')\n",
    "\n",
    "    # merge parking and weather data\n",
    "    df_park = df_park.merge(df_weather, left_index=True, right_index=True)\n",
    "    df_park.drop(['date_y'], axis=1, inplace=True)\n",
    "    df_park = df_park.rename(columns={'date_x' : 'date'})\n",
    "    df_park.set_index('date')\n",
    "\n",
    "    return df_park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapperswil = merge_weather(df_rapperswil, df_weather_rapperswil)\n",
    "df_burgdorf = merge_weather(df_burgdorf, df_weather_burgdorf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_lag_features(df_p):\n",
    "    df_park = df_p.copy()\n",
    "\n",
    "    # prepare lag data for weather_type\n",
    "    df_lags = pd.concat([df_park['weather'].shift(7),\n",
    "                         df_park['weather'].shift(3),\n",
    "                         df_park['weather'].shift(2),\n",
    "                         df_park['weather'].shift(1)], axis=1)\n",
    "\n",
    "    df_lags.columns = ['weather_t-7', 'weather_t-3', 'weather_t-2', 'weather_t-1']\n",
    "\n",
    "    # join lag df with parking and weather data \n",
    "    df_park = pd.concat([df_lags, df_park], axis=1)\n",
    "    \n",
    "    \n",
    "    # prepare lag data for temperature\n",
    "    df_temp_lags = pd.concat([df_park['temperature'].shift(7),\n",
    "                         df_park['temperature'].shift(3),\n",
    "                         df_park['temperature'].shift(2),\n",
    "                         df_park['temperature'].shift(1)], axis=1)\n",
    "\n",
    "    df_temp_lags.columns = ['temperature_t-7', 'temperature_t-3', 'temperature_t-2', 'temperature_t-1']\n",
    "    \n",
    "    # join lag df with parking and temperature data \n",
    "    df_park = pd.concat([df_temp_lags, df_park], axis=1)\n",
    "\n",
    "    # drop rows that contain NaN values caused by shifting\n",
    "    df_park.dropna(inplace=True)\n",
    "\n",
    "    # set datetime as index\n",
    "    df_park = df_park.set_index('date')\n",
    "\n",
    "\n",
    "    return df_park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rapperswil = weather_lag_features(df_rapperswil)\n",
    "df_burgdorf = weather_lag_features(df_burgdorf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Add public holiday information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boolean column by identifying whether data corresponds to a public holiday\n",
    "holidays = [i for i in df_holidays_rapperswil.date]\n",
    "df_rapperswil['holiday'] = df_rapperswil['date_only'].isin(holidays)\n",
    "\n",
    "holidays = [i for i in df_holidays_burgdorf.date]\n",
    "df_burgdorf['holiday'] = df_burgdorf['date_only'].isin(holidays)\n",
    "\n",
    "# convert true/false into integers\n",
    "df_rapperswil.replace({'holiday': {False: 0, True: 1}}, inplace=True)\n",
    "df_burgdorf.replace({'holiday': {False: 0, True: 1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length and number of columns of Rapperswil data: 2462, 25\n",
      "Length and number of columns of Burgdorf data: 191, 25\n"
     ]
    }
   ],
   "source": [
    "print('Length and number of columns of Rapperswil data: {}, {}'.format(len(df_rapperswil), len(df_rapperswil.columns)))\n",
    "print('Length and number of columns of Burgdorf data: {}, {}'.format(len(df_burgdorf), len(df_burgdorf.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df_p):\n",
    "    df_park = df_p.copy()\n",
    "\n",
    "    # prepare lag data \n",
    "    df_lags = pd.concat([df_park['occupancy_rate'].shift(7),\n",
    "                        df_park['occupancy_rate'].shift(3),\n",
    "                        df_park['occupancy_rate'].shift(2),\n",
    "                        df_park['occupancy_rate'].shift(1)], axis=1)\n",
    "\n",
    "    df_lags.columns = ['t-7', 't-3', 't-2', 't-1']\n",
    "\n",
    "    # join lag df with parking and lag data\n",
    "    df_park = pd.concat([df_lags, df_park], axis=1)\n",
    "\n",
    "    # drop rows that contain NaN values caused by shifting\n",
    "    df_park.dropna(inplace=True)\n",
    "\n",
    "    # set datetime as index\n",
    "    # df_park = df_park.set_index('date')\n",
    "\n",
    "    return df_park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapperswil = lag_features(df_rapperswil)\n",
    "df_burgdorf = lag_features(df_burgdorf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length and number of columns of Rapperswil data: 2455, 29\n",
      "Length and number of columns of Burgdorf data: 184, 29\n"
     ]
    }
   ],
   "source": [
    "print('Length and number of columns of Rapperswil data: {}, {}'.format(len(df_rapperswil), len(df_rapperswil.columns)))\n",
    "print('Length and number of columns of Burgdorf data: {}, {}'.format(len(df_burgdorf), len(df_burgdorf.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# format columns\n",
    "df_rapperswil = df_rapperswil.astype({'t-7': float,\n",
    "                                      't-3': float,\n",
    "                                      't-2': float,\n",
    "                                      't-1': float,\n",
    "                                      'occupancy_rate': float})\n",
    "\n",
    "df_rapperswil['date_only'] = pd.to_datetime(df_rapperswil['date_only'])\n",
    "df_burgdorf['date_only'] = pd.to_datetime(df_burgdorf['date_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to see if everything is ok\n",
    "# df_rapperswil\n",
    "# df_burgdorf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Feature to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapperswil.to_csv(os.path.join(data_path, \"features_rapperswil.csv\"), sep=\",\")\n",
    "df_burgdorf.to_csv(os.path.join(data_path, \"features_burgdorf.csv\"), sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
